{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9a6198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import hydra\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "import torchaudio as ta\n",
    "import musdb\n",
    "\n",
    "#library for class Wavset\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import torch as th\n",
    "import julius\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#library for loader()\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader, Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca78f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "musdb_p = '/workspace/helen/demucs'\n",
    "musdb_samplerate= 44100\n",
    "# wav=  # path to custom wav dataset\n",
    "segment= 11\n",
    "shift= 1\n",
    "train_valid= False\n",
    "full_cv= True\n",
    "samplerate= 44100\n",
    "channels= 2\n",
    "normalize= True\n",
    "metadata= './metadata'\n",
    "sources= ['drums', 'bass', 'other', 'vocals']\n",
    "EXT = \".wav\"\n",
    "MIXTURE = \"mixture\"\n",
    "\n",
    "batch_size= 6\n",
    "num_workers = 10\n",
    "world_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca549fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_musdb_valid():\n",
    "    # Return musdb valid set.\n",
    "    import yaml\n",
    "    setup_path = Path(musdb.__path__[0]) / 'configs' / 'mus.yaml'\n",
    "    setup = yaml.safe_load(open(setup_path, 'r'))\n",
    "    return setup['validation_tracks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93ddfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _track_metadata(track, sources, normalize=True, ext=EXT):\n",
    "    track_length = None\n",
    "    track_samplerate = None\n",
    "    mean = 0\n",
    "    std = 1\n",
    "    for source in sources + [MIXTURE]:\n",
    "        file = track / f\"{source}{ext}\"\n",
    "        try:\n",
    "            info = ta.info(str(file))\n",
    "        except RuntimeError:\n",
    "            print(file)\n",
    "            raise\n",
    "        length = info.num_frames\n",
    "        if track_length is None:\n",
    "            track_length = length\n",
    "            track_samplerate = info.sample_rate\n",
    "        elif track_length != length:\n",
    "            raise ValueError(\n",
    "                f\"Invalid length for file {file}: \"\n",
    "                f\"expecting {track_length} but got {length}.\")\n",
    "        elif info.sample_rate != track_samplerate:\n",
    "            raise ValueError(\n",
    "                f\"Invalid sample rate for file {file}: \"\n",
    "                f\"expecting {track_samplerate} but got {info.sample_rate}.\")\n",
    "        if source == MIXTURE and normalize:\n",
    "            try:\n",
    "                wav, _ = ta.load(str(file))\n",
    "            except RuntimeError:\n",
    "                print(file)\n",
    "                raise\n",
    "            wav = wav.mean(0)\n",
    "            mean = wav.mean().item()\n",
    "            std = wav.std().item()\n",
    "\n",
    "    return {\"length\": length, \"mean\": mean, \"std\": std, \"samplerate\": track_samplerate}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f2b7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_metadata(path, sources, normalize=True, ext=EXT):\n",
    "    \"\"\"\n",
    "    Build the metadata for `Wavset`.\n",
    "    Args:\n",
    "        path (str or Path): path to dataset.\n",
    "        sources (list[str]): list of sources to look for.\n",
    "        normalize (bool): if True, loads full track and store normalization\n",
    "            values based on the mixture file.\n",
    "        ext (str): extension of audio files (default is .wav).\n",
    "    \"\"\"\n",
    "\n",
    "    meta = {}\n",
    "    path = Path(path)\n",
    "    pendings = []\n",
    "    from concurrent.futures import ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(8) as pool:\n",
    "        for root, folders, files in os.walk(path, followlinks=True):\n",
    "            root = Path(root)\n",
    "            if root.name.startswith('.') or folders or root == path:\n",
    "                continue\n",
    "            name = str(root.relative_to(path))\n",
    "            pendings.append((name, pool.submit(_track_metadata, root, sources, normalize, ext)))\n",
    "            # meta[name] = _track_metadata(root, sources, normalize, ext)\n",
    "        for name, pending in tqdm.tqdm(pendings, ncols=120):\n",
    "            meta[name] = pending.result()\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9382b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio_channels(wav, channels=2):\n",
    "    \"\"\"Convert audio to the given number of channels.\"\"\"\n",
    "    *shape, src_channels, length = wav.shape\n",
    "    if src_channels == channels:\n",
    "        pass\n",
    "    elif channels == 1:\n",
    "        # Case 1:\n",
    "        # The caller asked 1-channel audio, but the stream have multiple\n",
    "        # channels, downmix all channels.\n",
    "        wav = wav.mean(dim=-2, keepdim=True)\n",
    "    elif src_channels == 1:\n",
    "        # Case 2:\n",
    "        # The caller asked for multiple channels, but the input file have\n",
    "        # one single channel, replicate the audio over all channels.\n",
    "        wav = wav.expand(*shape, channels, length)\n",
    "    elif src_channels >= channels:\n",
    "        # Case 3:\n",
    "        # The caller asked for multiple channels, and the input file have\n",
    "        # more channels than requested. In that case return the first channels.\n",
    "        wav = wav[..., :channels, :]\n",
    "    else:\n",
    "        # Case 4: What is a reasonable choice here?\n",
    "        raise ValueError('The audio file has less channels than requested but is not mono.')\n",
    "    return wav\n",
    "\n",
    "\n",
    "class Wavset:\n",
    "    def __init__(\n",
    "            self,\n",
    "            root, metadata, sources,\n",
    "            segment=None, shift=None, normalize=True,\n",
    "            samplerate=44100, channels=2, ext=EXT):\n",
    "        \"\"\"\n",
    "        Waveset (or mp3 set for that matter). Can be used to train\n",
    "        with arbitrary sources. Each track should be one folder inside of `path`.\n",
    "        The folder should contain files named `{source}.{ext}`.\n",
    "        Args:\n",
    "            root (Path or str): root folder for the dataset.\n",
    "            metadata (dict): output from `build_metadata`.\n",
    "            sources (list[str]): list of source names.\n",
    "            segment (None or float): segment length in seconds. If `None`, returns entire tracks.\n",
    "            shift (None or float): stride in seconds bewteen samples.\n",
    "            normalize (bool): normalizes input audio, **based on the metadata content**,\n",
    "                i.e. the entire track is normalized, not individual extracts.\n",
    "            samplerate (int): target sample rate. if the file sample rate\n",
    "                is different, it will be resampled on the fly.\n",
    "            channels (int): target nb of channels. if different, will be\n",
    "                changed onthe fly.\n",
    "            ext (str): extension for audio files (default is .wav).\n",
    "        samplerate and channels are converted on the fly.\n",
    "        \"\"\"\n",
    "        self.root = Path(root)\n",
    "        self.metadata = OrderedDict(metadata)\n",
    "        self.segment = segment\n",
    "        self.shift = shift or segment\n",
    "        self.normalize = normalize\n",
    "        self.sources = sources\n",
    "        self.channels = channels\n",
    "        self.samplerate = samplerate\n",
    "        self.ext = ext\n",
    "        self.num_examples = []\n",
    "        for name, meta in self.metadata.items():\n",
    "            track_duration = meta['length'] / meta['samplerate']\n",
    "            if segment is None or track_duration < segment:\n",
    "                examples = 1\n",
    "            else:\n",
    "                examples = int(math.ceil((track_duration - self.segment) / self.shift) + 1)\n",
    "            self.num_examples.append(examples)\n",
    "#samplerate = number of sample per second\n",
    "#length = number of sample\n",
    "    def __len__(self):\n",
    "        return sum(self.num_examples)\n",
    "\n",
    "    def get_file(self, name, source):\n",
    "        return self.root / name / f\"{source}{self.ext}\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        print(len(self.metadata))\n",
    "        print(len(self.num_examples)\n",
    "        for name, examples in zip(self.metadata, self.num_examples):           \n",
    "            if index >= examples:\n",
    "                index -= examples\n",
    "                continue\n",
    "            meta = self.metadata[name]\n",
    "            num_frames = -1\n",
    "            offset = 0\n",
    "            if self.segment is not None:\n",
    "                offset = int(meta['samplerate'] * self.shift * index)\n",
    "                num_frames = int(math.ceil(meta['samplerate'] * self.segment))\n",
    "            wavs = []\n",
    "            for source in self.sources:\n",
    "                file = self.get_file(name, source)\n",
    "                wav, _ = ta.load(str(file), frame_offset=offset, num_frames=num_frames)\n",
    "                wav = convert_audio_channels(wav, self.channels)\n",
    "                wavs.append(wav)\n",
    "\n",
    "            example = th.stack(wavs)\n",
    "            example = julius.resample_frac(example, meta['samplerate'], self.samplerate)\n",
    "            if self.normalize:\n",
    "                example = (example - meta['mean']) / meta['std']\n",
    "            if self.segment:\n",
    "                length = int(self.segment * self.samplerate)\n",
    "                example = example[..., :length]\n",
    "                example = F.pad(example, (0, length - example.shape[-1]))\n",
    "            return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee321eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_musdb_wav_datasets():\n",
    "    \"\"\"Extract the musdb dataset from the XP arguments.\"\"\"\n",
    "    sig = hashlib.sha1(str(musdb_p).encode()).hexdigest()[:8]\n",
    "    metadata_file = Path('./metadata') / ('musdb_' + sig + \".json\")\n",
    "    root = Path(musdb_p) / \"train\"\n",
    "#     if not metadata_file.is_file() and distrib.rank == 0:\n",
    "    if not metadata_file.is_file():\n",
    "        metadata_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "        metadata = build_metadata(root, sources)\n",
    "        json.dump(metadata, open(metadata_file, \"w\"))\n",
    "#     if distrib.world_size > 1:\n",
    "#         distributed.barrier()\n",
    "    metadata = json.load(open(metadata_file))\n",
    "\n",
    "    valid_tracks = _get_musdb_valid()\n",
    "    if train_valid:\n",
    "        metadata_train = metadata\n",
    "    else:\n",
    "        metadata_train = {name: meta for name, meta in metadata.items() if name not in valid_tracks}\n",
    "    metadata_valid = {name: meta for name, meta in metadata.items() if name in valid_tracks}\n",
    "    if full_cv:\n",
    "        kw_cv = {}\n",
    "    else:\n",
    "        kw_cv = {'segment': segment, 'shift': shift}\n",
    "\n",
    "    return root, \n",
    "\n",
    "\n",
    "train_set = Wavset(root, metadata_train, sources,\n",
    "                   segment=segment, shift=shift,\n",
    "                   samplerate=samplerate, channels=channels,\n",
    "                   normalize=normalize)\n",
    "valid_set = Wavset(root, metadata_valid, [MIXTURE] + list(sources),\n",
    "                   samplerate=samplerate, channels=channels,\n",
    "                   normalize=normalize, **kw_cv)\n",
    "#manually comment out function from distrib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1fb2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set = get_musdb_wav_datasets()\n",
    "# train_set = get_musdb_wav_datasets()\n",
    "#train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d2b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Wavset(root, metadata_train, sources,\n",
    "                       segment=segment, shift=shift,\n",
    "                       samplerate=samplerate, channels=channels,\n",
    "                       normalize=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12a8fb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "[259, 203, 251, 215, 8, 181, 348, 233, 285, 32, 196, 187, 150, 229, 228, 212, 346, 301, 219, 293, 198, 247, 19, 178, 27, 159, 285, 280, 182, 105, 505, 266, 244, 193, 201, 292, 16, 137, 619, 157, 389, 186, 248, 249, 159, 167, 164, 306, 202, 274, 10, 245, 403, 250, 25, 209, 162, 232, 223, 4, 382, 239, 192, 239, 115, 238, 27, 221, 182, 27, 233, 269, 180, 294, 426, 195, 308, 172, 66, 280, 255, 246, 230, 317, 8, 234]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 485100])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[45].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36d619a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "[259, 203, 251, 215, 8, 181, 348, 233, 285, 32, 196, 187, 150, 229, 228, 212, 346, 301, 219, 293, 198, 247, 19, 178, 27, 159, 285, 280, 182, 105, 505, 266, 244, 193, 201, 292, 16, 137, 619, 157, 389, 186, 248, 249, 159, 167, 164, 306, 202, 274, 10, 245, 403, 250, 25, 209, 162, 232, 223, 4, 382, 239, 192, 239, 115, 238, 27, 221, 182, 27, 233, 269, 180, 294, 426, 195, 308, 172, 66, 280, 255, 246, 230, 317, 8, 234]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0024, 0.0024, 0.0024,  ..., 0.0024, 0.0024, 0.0024],\n",
       "         [0.0024, 0.0024, 0.0024,  ..., 0.0024, 0.0024, 0.0024]],\n",
       "\n",
       "        [[0.0024, 0.0024, 0.0024,  ..., 0.0024, 0.0024, 0.0024],\n",
       "         [0.0024, 0.0024, 0.0024,  ..., 0.0024, 0.0024, 0.0024]],\n",
       "\n",
       "        [[0.0024, 0.0024, 0.0024,  ..., 0.0024, 0.0024, 0.0024],\n",
       "         [0.0024, 0.0024, 0.0024,  ..., 0.0024, 0.0024, 0.0024]],\n",
       "\n",
       "        [[0.0024, 0.0024, 0.0024,  ..., 0.0024, 0.0024, 0.0024],\n",
       "         [0.0024, 0.0024, 0.0024,  ..., 0.0024, 0.0024, 0.0024]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ccdc53a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ffc0cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 11301609])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e37b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(train_set):    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8c338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(dataset, batch_size , shuffle=False, klass=DataLoader, **kwargs):\n",
    "    \"\"\"\n",
    "    Create a dataloader properly in case of distributed training.\n",
    "    If a gradient is going to be computed you must set `shuffle=True`.\n",
    "    \"\"\"\n",
    "    if world_size == 1:\n",
    "        return klass(dataset, batch_size=batch_size, shuffle=shuffle, **kwargs)\n",
    "\n",
    "    if shuffle:\n",
    "        # train means we will compute backward, we use DistributedSampler\n",
    "        sampler = DistributedSampler(dataset)\n",
    "        # We ignore shuffle, DistributedSampler already shuffles\n",
    "        return klass(dataset, batch_size=batch_size, **kwargs, sampler=sampler)\n",
    "    else:\n",
    "        # We make a manual shard, as DistributedSampler otherwise replicate some examples\n",
    "        dataset = Subset(dataset, list(range(rank, len(dataset), world_size)))\n",
    "        return klass(dataset, batch_size=batch_size, shuffle=shuffle, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a57ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = loader(\n",
    "        train_set, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff05a333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7feb284de730>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:demucs] *",
   "language": "python",
   "name": "conda-env-demucs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
